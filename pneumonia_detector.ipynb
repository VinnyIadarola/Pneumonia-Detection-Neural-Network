{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77d854e",
   "metadata": {},
   "source": [
    "# Imports and Defines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ef946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13844fb8",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23016c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 1000\n",
    "EPOCHS = 5\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "DROP_OUT_P = 0.2\n",
    "BATCH_SIZE = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cb06c",
   "metadata": {},
   "source": [
    "# Database Setups and Images Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41fecbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1857, 1317) RGB 0\n",
      "(2031, 1837) RGB 0\n"
     ]
    }
   ],
   "source": [
    "## TODO Taken from hw5 p4 refactor size \n",
    "\n",
    "BASE_PATH = './chest_xray/processed/'\n",
    "\n",
    "db_train = datasets.ImageFolder(root=BASE_PATH+'train', transform=None)\n",
    "db_val = datasets.ImageFolder(root=BASE_PATH+'val', transform=None)\n",
    "db_test = datasets.ImageFolder(root=BASE_PATH+'test', transform=None)\n",
    "\n",
    "img1, y1 = db_train[0]\n",
    "img2, y2 = db_train[1]\n",
    "\n",
    "\n",
    "print(img1.size, img1.mode, y1)\n",
    "print(img2.size, img2.mode, y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76e95dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train.transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),    \n",
    "    transforms.RandomResizedCrop(size=[IMAGE_SIZE, IMAGE_SIZE], scale=(0.5,1.)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(             # Normalize using ImageNet's mean and standard deviation\n",
    "        mean=0.485,\n",
    "        std=0.225\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "db_val.transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),   \n",
    "    # Resize the short side of the image to 256\n",
    "    transforms.CenterCrop([IMAGE_SIZE, IMAGE_SIZE]),       # Crop a center patch of the image of size 224x224\n",
    "    transforms.ToTensor(),            # Convert the image to tensor format\n",
    "    transforms.Normalize(             # Normalize using ImageNet's mean and standard deviation\n",
    "        mean= 0.406,\n",
    "        std=0.225\n",
    "    )\n",
    "])\n",
    "\n",
    "db_test.transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),           # Resize the short side of the image to 256\n",
    "    transforms.CenterCrop([IMAGE_SIZE, IMAGE_SIZE]),       # Crop a center patch of the image of size 224x224\n",
    "    transforms.ToTensor(),            # Convert the image to tensor format\n",
    "    transforms.Normalize(             # Normalize using ImageNet's mean and standard deviation\n",
    "        mean=0.485,\n",
    "        std=0.229\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec80885",
   "metadata": {},
   "source": [
    "## Training and Testing Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7eb8adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def fit_one_epoch(model, opt, loader):\n",
    "    model.train(True)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    losses, accuracies = [], []\n",
    "    for images, labels in tqdm.tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(images)\n",
    "        l = loss(pred, labels)\n",
    "        acc = (pred.argmax(1) == labels).float().mean()\n",
    "\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        losses.append(l.detach().item())\n",
    "        accuracies.append(acc.detach().item())\n",
    "    return np.mean(losses), np.mean(accuracies)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(model, loader):\n",
    "    model.train(False)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    accuracies, losses = [], []\n",
    "    for images, labels in tqdm.tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(images)\n",
    "        acc = (pred.argmax(1) == labels).float().mean()\n",
    "        l = loss(pred, labels)\n",
    "\n",
    "        accuracies.append(acc.detach().item())\n",
    "        losses.append(l.detach().item())\n",
    "    return np.mean(losses), np.mean(accuracies)\n",
    "\n",
    "\n",
    "def fit(model, loader_train, loader_val, epochs=50, opt=None):\n",
    "    assert opt is not None\n",
    "    hist_tr_loss, hist_val_loss, hist_tr_acc, hist_val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        val_l, val_acc = eval(model, loader_val)\n",
    "        tr_l, tr_acc = fit_one_epoch(model, opt, loader_train)\n",
    "\n",
    "        print(f\"Finished epoch {epoch} of {epochs}: Train Loss = {tr_l:.3f}  Val Loss = {val_l:.3f}   Train Acc = {tr_acc:.3f}   Val Acc = {val_acc:.3f}\", flush=True)\n",
    "        hist_tr_loss.append(tr_l)\n",
    "        hist_val_loss.append(val_l)\n",
    "        hist_tr_acc.append(tr_acc)\n",
    "        hist_val_acc.append(val_acc)\n",
    "    return hist_tr_loss, hist_val_loss, hist_tr_acc, hist_val_acc\n",
    "\n",
    "\n",
    "def plot_training_history(hist_tr_loss, hist_val_loss, hist_tr_acc, hist_val_acc):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist_tr_acc, label='train accuracy')\n",
    "    plt.plot(hist_val_acc, label='val accuracy')\n",
    "    plt.ylim([0.4, 1.05])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist_tr_loss, label='train loss')\n",
    "    plt.plot(hist_val_loss, label='val loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1d301",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1570ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=(5, 5), padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    nn.Conv2d(32, 64, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Dropout(p=DROP_OUT_P, inplace=False),\n",
    "    \n",
    "    nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "    nn.Conv2d(64, 64, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3904576, 2) ## Binary Classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d93e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO None sequential version for making variable lengths \n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        convs,\n",
    "        max_pools,\n",
    "        hidden_depth=10, \n",
    "        num_classes=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        layers = []\n",
    "        # input/first hidden\n",
    "        layers.append(nn.Conv2d(\n",
    "            convs[0]['in_channels'],\n",
    "            convs[0]['out_channels'], \n",
    "            kernel_size=convs[0]['kernal_size'], \n",
    "            padding=convs[0]['padding']\n",
    "        ))\n",
    "        \n",
    "        # additional hidden layers - the one input\n",
    "        for i in range(1, hidden_depth - 1):\n",
    "            layers.append(nn.MaxPool2d(\n",
    "                kernel_size=max_pools[i]['kernal_size'], \n",
    "                padding=max_pools[i]['padding']\n",
    "            ))\n",
    "            \n",
    "            layers.append(nn.Conv2d(\n",
    "                convs[i]['in_channels'],\n",
    "                convs[i]['out_channels'], \n",
    "                kernel_size=convs[i]['kernal_size'], \n",
    "                padding=convs[i]['padding']\n",
    "            ))              \n",
    "\n",
    "        ## come up with automated way to calcualte falttened size\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "        self.out = nn.Linear(..., num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88522eff",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d86d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:13<00:00,  7.04s/it]\n",
      " 29%|██▉       | 47/163 [41:33<2:53:04, 89.52s/it]"
     ]
    }
   ],
   "source": [
    "loader_train = DataLoader(db_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "loader_val = DataLoader(db_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "loader_test = DataLoader(db_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "hist_tr_loss, hist_test_loss, hist_tr_acc, hist_test_acc = fit(model, loader_train, loader_val, epochs=EPOCHS, opt=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ba411",
   "metadata": {},
   "source": [
    "## Learning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d44ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, acc = eval(model, loader_test)\n",
    "plot_training_history(hist_tr_loss, hist_test_loss, hist_tr_acc, hist_test_acc)\n",
    "print(f'Test accuracy: {acc*100:.2f}%')\n",
    "print(f'Test loss: {l:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
